---
title: "ggplot-sf"
author: "H. Sherry Zhang"
date: '2022-05-21'
slug: []
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2022-05-21T22:49:21+10:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, 
                      message = FALSE,
                      fig.align = "center")
library(SpatialEpiApp)
library(SpatialEpi)
library(tidyverse)
library(sf)
library(patchwork)
```

We all see faceted plots and don't tell me you don't, unless you never use a calendar; We all see maps and don't tell me you don't, unless you never get to somewhere. Here I have an interesting observation on faceted maps for you. 

```{r}
ohio <- read_sf(system.file("SpatialEpiApp/data/Ohio/fe_2007_39_county/fe_2007_39_county.shp", 
                           package = "SpatialEpiApp")) %>% 
  select(NAME, geometry)
```

This example comes from [Chapter 7 of Paula Moraga's book Geospatial Health Data: Modeling and Visualization with R-INLA and Shiny](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html) and I have simplified it for my demonstration. In essence, there are two datasets: 

1. A map data (`ohio`) with `r nrow(ohio)` Ohio counties in an `sf` object: 

```{r}
ohio
```

2. A lung cancer data with standardized incidence ratios (SIRs) calculated for each county across 21 years (1968 - 1988):

```{r}
ohio_raw <- read_csv(system.file("SpatialEpiApp/data/Ohio/dataohiocomplete.csv", 
                    package = "SpatialEpiApp"))

dt <- ohio_raw %>% arrange(county, year, gender, race) 
res <- dt %>% 
  group_by(NAME, year) %>% 
  summarise(Y = sum(y)) %>% 
  ungroup()

n_strata <- 4
E <- expected(population = dt$n, cases = dt$y, n.strata = n_strata)
nyears <- length(unique(ohio_raw$year))
countiesE <- rep(unique(ohio_raw$NAME), each = nyears)

ncounties <- length(unique(ohio_raw$NAME))
yearsE <- rep(unique(ohio_raw$year), time = ncounties)

sir <- tibble(county = countiesE, year = yearsE, E = E) %>% 
  left_join(res, by = c("county" = "NAME", "year")) %>% 
  mutate(SIR = Y/E) %>% 
  select(county, year, SIR)
```

```{r}
sir
```

The details on calculating SIR is not the focus of this post and Section [7.1](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html#sec-arealdataexamplest) to [7.2](https://www.paulamoraga.com/book-geospatial/sec-arealdataexamplest.html#data-preparation-1) of Paula's book has detailed all the steps you need if interested. 

What we would like to do here is to show those SIR values of each county on the map across year. This would require us to join the two datasets, supply the combined data into ggplot, plot the underlying map, fill the county polygon with `SIR`,  make facets with `year`, and lastly add a few tweaks on theme and the scale of fill. Let's give this plot a name, say `target`: 

```{r echo = TRUE}
combined <- ohio %>% 
  left_join(sir, by = c("NAME" = "county"))

target <- combined %>% 
  ggplot() + 
  geom_sf(aes(fill = SIR)) +
  facet_wrap(~year, dir = "h", ncol = 7) +
  ggtitle("SIR") + 
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  ) +
  scale_fill_gradient2(
    midpoint = 1, low = "blue", mid = "white", high = "red"
  )

target
```

Easy peasy. 

But, have you thought about how long it would take to bring this plot to you?

```{r}
combined <- ohio %>% left_join(sir, by = c("NAME" = "county")) 

make_plot <- function(data){
  data %>% 
    ggplot() + 
    geom_sf(aes(fill = SIR)) + 
    theme_bw() +
    facet_wrap(~year, dir = "h", ncol = 7) +
    theme(
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
    )  + 
    scale_fill_gradient2(
      limits = c(0, range(combined$SIR)[2]),
      midpoint = 1, low = "blue", mid = "white", high = "red", 
    )
}

bench_plot <- function(data){
  p <- make_plot(data)
  benchplot(p)
}

get_total <- function(df) as.numeric(df$elapsed[5])
get_draw <- function(df) as.numeric(df$elapsed[4])
```

```{r}
p1 <- ohio %>% 
  ggplot() + 
  geom_sf() +  
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  )

dt2 <- combined %>% filter(year == 1968)
dt3 <- combined %>% filter(year %in% c(1968, 1969))
dt4 <- combined
```

```{r eval = FALSE}
dev.new()
t1 <- benchplot(p1)
while (dev.cur()>1) dev.off()
t234 <- map(list(dt2 = dt2, dt3 = dt3, dt4 = dt4), ~{
  dev.new()
  out <- .x %>% bench_plot()
  while (dev.cur()>1) dev.off()
  return(out)
})

time <- c(list(dt1 = t1), t234)

save(time, file = here::here("content/post/2022-05-21-ggplot-sf/time.rda"))
```

```{r}
load("time.rda")
```

Let me show you some components of this plot as benchmarks, here I have: 

  1) `P0`: a single map object (left): **`r get_total(time$dt1)` secs**
  
  2) `P1`: a single year (1968) with SIR filled (mid): **`r get_total(time$dt2)` secs**, and
  
  3) `P2`: two years (1968 & 1969) with SIR filled in facets (right): **`r get_total(time$dt3)` secs**

```{r fig.width=10, fig.height=3.5}
p5 <- p1 + 
  labs(title = "P0: a single map object",
       subtitle = glue::glue("{round(get_total(time$dt1), 5)} secs"))

p6 <- dt2 %>% 
  make_plot() +
  labs(title = "P1: a single year (1968)",
       subtitle = glue::glue("{round(get_total(time$dt2),5)} secs"))

p7 <- dt3 %>% 
  make_plot() + 
  labs(title = "P2: two years (1968 & 1969) with SIR filled in facets",
       subtitle = glue::glue("{round(get_total(time$dt3),5)} secs")) 

(p5 | p6 | p7) + 
  plot_layout(guides = 'collect', widths = c(1, 1, 2)) &
  theme(legend.position='right')  
```

okay, now it is your time to make a guess: 

 - ~1 or 2 second? Ideally if the same map is rendered in parallel across all facets, the increment of time would be marginal. 
 
 - ~`r round(get_total(time$dt2) + (get_total(time$dt3) - get_total(time$dt2)) * 21)` seconds? The increment of rendering another facet from 2) to 3) is `r round(get_total(time$dt3),5) - round(get_total(time$dt2),5)` (`r round(get_total(time$dt3),5)`-`r round(get_total(time$dt2),5)`) sec.  Projecting that into 20 more facets will give us: `r round(get_total(time$dt2),5)` + (`r round(get_total(time$dt3),5)`-`r round(get_total(time$dt2),5)`) * 20 = `r round(get_total(time$dt2) + (get_total(time$dt3) - get_total(time$dt2)) * 21,5)` sec. 
 
 - 30 seconds, 40 seconds, 1 minutes? I don't know. I just run your code and have waited a while for this plot to appear. 
 
## Let's reveal the answer

There are different ways to check the execution time of a command and here we use `ggplot2::benchplot()`, which is printed below: 

```{r}
ggplot2::benchplot
```

The advantage of `ggplot2::benchplot()` over other alternative is that it can break down the time by building, rendering, and drawing: 

```{r echo = TRUE, eval = FALSE}
benchplot(target)
```

```{r}
time$dt4
```

WOW, I do not expect it to take `r round(get_total(time$dt4), 5)` secs to get our plot! 

## How come it take that long? 

We can take a look at the time decomposition of our target plot along with the three benchmark plots. This would give us an idea of where our target plot take long: 

```{r fig.width=10, fig.height=3.5}
dt <- do.call(bind_rows, time) %>% 
  as_tibble() %>% 
  mutate(plot = factor(rep(paste0("p", c(0:2, 21)), each = 5)),
         step = factor(step, levels = c("construct", "build","render", "draw", "TOTAL"))) %>% 
  filter(step != "construct") 

dt %>% 
  ggplot(aes(x = plot, y = sqrt(elapsed), color = plot, fill = plot)) + 
  geom_col() + 
  geom_text(aes(y = sqrt(elapsed) - 0.1, label = round(elapsed, 2)), color = "black")+ 
  facet_wrap(vars(step), nrow = 1)  + 
  scale_y_continuous(breaks = seq(0, 6, 1)) + 
  labs(y = "square root of elapsed time")
```

Here `p0` to `p2` is the three benchmark plots from left to right and `p21` is the target plot (since it has 21 facets). Notice here on the y-axis is the **square root** of elapsed time and the text on each bar is the **actual** elapsed time. 

Building and rendering time looks fine and the last plot is taking a considerable large amount of time in the drawing.

We could also look at the drawing time with an addition of one facet each time. The function `benchplot()` only evaluates the plot once and to get an average result of the performance, each simulation is repeated for 100 times. Here is the script used: 

```{r eval = FALSE}
combined <- ohio %>% left_join(sir, by = c("NAME" = "county")) 

make_plot <- function(data){
  data %>% 
    ggplot() + 
    geom_sf(aes(fill = SIR)) + 
    theme_bw() +
    facet_wrap(~year, dir = "h", ncol = 7) +
    theme(
      axis.text.x = element_blank(),
      axis.text.y = element_blank(),
      axis.ticks = element_blank(),
    )  + 
    scale_fill_gradient2(
      limits = c(0, range(combined$SIR)[2]),
      midpoint = 1, low = "blue", mid = "white", high = "red", 
    )
}

bench_plot <- function(data){
  p <- make_plot(data)
  benchplot(p)
}

time_all10 <- map_dfr(1:10, function(id){
  res <- map_dfr(year, function(y){
    dev.new()
    dt <- combined %>% filter(year <= y)
    out <- dt %>% bench_plot()
    while (dev.cur()>1) dev.off()
    return(out)
}, .id = "plot")
  return(res %>% mutate(id = id))
}, .id = "id")
```

The object `combined` joins the `ohio` map data with the `sir` data;  the function `make_plot()` specialises in creating the target plot; and the function `bench_plot()` first creates the plot with `make_plot()` and then calls `benchplot()` to evaluate the execution time. This evaluation happens with one facet per increment and repeated for 100 times. Notice here we open a new plot device (`dev.new()`) and close it `while (dev.cur()>1) dev.off()` to remove the effect of [...]. 

Now we can make a violine/ boxplot to see the increment of drawing time with an additional facet: 


<!-- ```{r} -->
<!-- #load("time_all100.rda") -->
<!-- ``` -->

<!-- ```{r eval = FALSE} -->
<!-- do.call(bind_rows, time_all) %>%  -->
<!--   mutate(plot = rep(1:21, each = 5), id = 4) %>%  -->
<!--   # bind_rows(time_all100 %>% as_tibble() %>%  -->
<!--   # mutate(plot = as.numeric(plot), id = as.numeric(id))) %>%  -->
<!--   # bind_rows(time_all1) %>%  -->
<!--   filter(step == "draw") %>%  -->
<!--   ggplot(aes(x = plot, y = elapsed, group = plot)) +  -->
<!--   geom_point() -->
<!-- ``` -->

[...]


This reminds me of the fact that if I throw an unrealistic large number of facets to ggplot and ask it to draw the plot for me, ggplot will be grumpy. Let's look at how many points we have asked it to draw. In `ggplot2::benchplot()`, `draw <- system.time(grid.draw(grob))` is used to check the drawing time and `sf` has a function `st_as_grob()` to convert the simple feature object into a grob ready for `grid.draw()` to plot: 

```{r}
grob <- sf::st_as_grob(combined$geometry)
grob$x %>% length()
```

This is also the value of number of points in the combined data, which can be checked with `st_coordinates()`: 

```{r}
combined %>% st_coordinates() %>% nrow()
```

It looks like we are indeed being a little bit mean and are overworking ggplot. A little trick we can do here is to simplify the polygon a little bit, with `rmapshaper:: ms_simplify()`, which, by default, only keep 1 percent of the points from the polygons: 

```{r results='hide'}
ohio2 <- ohio %>% rmapshaper::ms_simplify()

combined2 <- ohio2 %>% left_join(sir, by = c("NAME" = "county"))

target2 <- combined2 %>% 
  ggplot() + 
  geom_sf(aes(fill = SIR)) +
  facet_wrap(~year, dir = "h", ncol = 7) +
  ggtitle("SIR") + 
  theme_bw() +
  theme(
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  ) +
  scale_fill_gradient2(
    midpoint = 1, low = "blue", mid = "white", high = "red"
  )

dev.new()
res <- benchplot(target2)    
while (dev.cur()>1) dev.off()
```

```{r}
as_tibble(res)
```

WOW, now we instantly get our plot and `benchplot()` says  

And guess how the plot looks like after the simplification? 

```{r}
target2
```

I can't even tell it from the origin plot! 

So, we didn't really solve why  how to speed up the drawing of grid graphic. But at least for now, the simplification trick works for us to get away with the problem. 

